{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d236814-10b9-40ac-9239-003fd72034e2",
   "metadata": {},
   "source": [
    "## First similarity study -> Collaborative filtering with different formulas for distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8447061-1f7a-4a5c-a248-795d1875e064",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac6119e-a800-435b-aa4a-4467414369dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy import sparse\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24d2c0-8c6d-4619-a2f8-8f5ea3548605",
   "metadata": {},
   "source": [
    "#### Loading the datasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b271eaf-b9a8-4296-90a4-104e25ea2069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Election details Index(['ID', 'project_id', 'project_title', 'created_at', 'checked_out_at',\n",
      "       'project_url', 'vote_finished'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "electionDetailsDF = pd.read_csv('projectDetails.csv', sep=\";\")\n",
    "print(\"Election details\",electionDetailsDF.columns,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8554c77-d6b8-42d8-b318-b0bf7fa7a3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_id  4    5    6    7    8    9    10   11   12   13   ...  194  195  \\\n",
      "ID                                                            ...             \n",
      "9             0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "11            0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "12            0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "13            0    1    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "15            0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "5228          0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "5229          0    0    0    1    0    0    0    1    0    0  ...    0    0   \n",
      "5230          0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "5231          0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "5232          0    0    0    0    0    0    0    0    0    0  ...    0    0   \n",
      "\n",
      "project_id  196  197  198  199  200  201  202  203  \n",
      "ID                                                  \n",
      "9             0    0    0    0    0    0    0    0  \n",
      "11            0    0    0    0    0    0    0    0  \n",
      "12            0    0    0    0    0    0    0    0  \n",
      "13            0    0    0    0    0    0    0    0  \n",
      "15            0    0    0    0    0    0    0    0  \n",
      "...         ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "5228          0    0    0    0    0    0    0    0  \n",
      "5229          0    0    0    0    0    0    0    0  \n",
      "5230          0    0    0    0    0    0    0    0  \n",
      "5231          0    0    0    0    0    0    0    0  \n",
      "5232          0    0    0    0    0    0    0    0  \n",
      "\n",
      "[4532 rows x 199 columns]\n"
     ]
    }
   ],
   "source": [
    "##Creating the binary matrix\n",
    "voter_matrix = pd.crosstab(electionDetailsDF['ID'], electionDetailsDF['project_id'])\n",
    "\n",
    "print(voter_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066257bc-233d-49c0-8b7d-ac53f0520296",
   "metadata": {},
   "source": [
    "**Item-item collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5237ec89-47bd-49ac-bbf1-5343cd43e119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          cosine        pearson      euclidean      manhattan       tanimoto  \\\n",
      "0    (87, 0.677)   (87, 0.6731)   (87, 0.2109)   (87, 0.0524)   (87, 0.5116)   \n",
      "1   (86, 0.6361)   (86, 0.6313)   (86, 0.2008)     (86, 0.04)   (86, 0.4663)   \n",
      "2   (90, 0.1316)   (90, 0.1245)   (50, 0.1736)    (50, 0.026)   (90, 0.0656)   \n",
      "3   (81, 0.0966)   (81, 0.0889)  (176, 0.1736)   (176, 0.026)   (81, 0.0455)   \n",
      "4    (82, 0.087)   (82, 0.0777)  (187, 0.1736)   (187, 0.026)   (82, 0.0441)   \n",
      "5   (89, 0.0742)   (89, 0.0697)  (181, 0.1731)  (181, 0.0259)   (83, 0.0317)   \n",
      "6   (83, 0.0658)   (83, 0.0578)   (55, 0.1725)  (178, 0.0257)   (89, 0.0267)   \n",
      "7  (186, 0.0355)  (186, 0.0305)  (168, 0.1725)   (55, 0.0256)   (186, 0.013)   \n",
      "8   (74, 0.0221)   (183, 0.014)   (46, 0.1715)  (168, 0.0256)   (74, 0.0104)   \n",
      "9  (183, 0.0214)   (74, 0.0131)  (178, 0.1715)   (46, 0.0252)  (183, 0.0102)   \n",
      "\n",
      "         hamming  \n",
      "0   (87, 0.9945)  \n",
      "1   (86, 0.9916)  \n",
      "2   (50, 0.9861)  \n",
      "3  (176, 0.9861)  \n",
      "4  (178, 0.9861)  \n",
      "5  (181, 0.9861)  \n",
      "6  (187, 0.9861)  \n",
      "7   (55, 0.9859)  \n",
      "8  (168, 0.9859)  \n",
      "9   (46, 0.9857)  \n"
     ]
    }
   ],
   "source": [
    "##Magnitude vector to apply normalization\n",
    "magnitude = np.sqrt(np.square(voter_matrix).sum(axis=1))\n",
    "\n",
    "##Unit vector (normalized matrix)\n",
    "voter_matrix = voter_matrix.divide(magnitude, axis='index')\n",
    "\n",
    "def calculate_similarity_cosine(data_items):\n",
    "    \"\"\"\n",
    "    Calculate the column-wise cosine similarity for a sparse\n",
    "    matrix. Return a new dataframe matrix with similarities.\n",
    "    \"\"\"\n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    similarities = cosine_similarity(data_sparse.transpose())\n",
    "    sim = pd.DataFrame(data=similarities, index = data_items.columns, columns=data_items.columns)\n",
    "    return sim\n",
    "\n",
    "def calculate_similarity_jaccard(data_items):\n",
    "    \"\"\"\n",
    "    Calculate the column-wise cosine similarity for a sparse\n",
    "    matrix. Return a new dataframe matrix with similarities.\n",
    "    \"\"\"\n",
    "    distances = pdist(data_items, metric='jaccard')\n",
    "    similarities = 1 - squareform(distances)\n",
    "    return pd.DataFrame(similarities, index=data_items.index, columns=data_items.index)\n",
    "\n",
    "def calculate_similarity_pearson(data_items):\n",
    "    \"\"\"\n",
    "    Calculate the column-wise cosine similarity for a sparse\n",
    "    matrix. Return a new dataframe matrix with similarities.\n",
    "    \"\"\"\n",
    "    similarities = data_items.corr(method='pearson')\n",
    "    return similarities\n",
    "\n",
    "def calculate_similarity_euclidean(data_items):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance and convert to similarity.\n",
    "    Similarity = 1 / (1 + distance)\n",
    "    \"\"\"\n",
    "    distances = pdist(data_items.T, metric='euclidean')\n",
    "    similarities = 1 / (1 + squareform(distances))\n",
    "    return pd.DataFrame(similarities, index=data_items.columns, columns=data_items.columns)\n",
    "\n",
    "def calculate_similarity_manhattan(data_items):\n",
    "    distances = pdist(data_items.T, metric='cityblock')\n",
    "    similarities = 1 / (1 + squareform(distances))\n",
    "    return pd.DataFrame(similarities, index=data_items.columns, columns=data_items.columns)\n",
    "\n",
    "def calculate_similarity_tanimoto(data_items):\n",
    "    \"\"\"\n",
    "    Generalized Jaccard (Tanimoto) similarity for non-binary data.\n",
    "    \"\"\"\n",
    "    A = data_items.values.T\n",
    "    dot_product = A @ A.T\n",
    "    square_sum = np.sum(A ** 2, axis=1).reshape(-1, 1)\n",
    "    denominator = square_sum + square_sum.T - dot_product\n",
    "    similarity = dot_product / (denominator + 1e-10)\n",
    "    return pd.DataFrame(similarity, index=data_items.columns, columns=data_items.columns)\n",
    "\n",
    "def calculate_similarity_adjusted_cosine(data_items):\n",
    "    \"\"\"\n",
    "    Adjusted cosine similarity - subtract mean user rating before computing cosine similarity.\n",
    "    \"\"\"\n",
    "    mean_user_ratings = data_items.mean(axis=1)\n",
    "    adjusted_data = data_items.sub(mean_user_ratings, axis=0).fillna(0)\n",
    "    data_sparse = sparse.csr_matrix(adjusted_data)\n",
    "    similarities = cosine_similarity(data_sparse.T)\n",
    "    return pd.DataFrame(similarities, index=data_items.columns, columns=data_items.columns)\n",
    "\n",
    "def calculate_similarity_hamming(data_items):\n",
    "    \"\"\"\n",
    "    Calculate Hamming similarity (1 - Hamming distance) between columns (items).\n",
    "    Assumes binary data.\n",
    "    \"\"\"\n",
    "    # Transpose so we're comparing items (columns)\n",
    "    distances = pdist(data_items.T, metric='hamming')\n",
    "    similarities = 1 - squareform(distances)\n",
    "    return pd.DataFrame(similarities, index=data_items.columns, columns=data_items.columns)\n",
    "\n",
    "def compare_similarity_metrics(data_items,project_id,top_n=11):\n",
    "    cosine = calculate_similarity_cosine(voter_matrix)\n",
    "    jaccard = calculate_similarity_jaccard(voter_matrix)\n",
    "    pearson = calculate_similarity_pearson(voter_matrix)\n",
    "    euclidean = calculate_similarity_euclidean(voter_matrix)\n",
    "    manhattan = calculate_similarity_manhattan(voter_matrix)\n",
    "    tanimoto = calculate_similarity_tanimoto(voter_matrix)\n",
    "    hamming = calculate_similarity_hamming(voter_matrix)\n",
    "\n",
    "    similarity_comparator = {\n",
    "        \"cosine\":list(cosine.loc[project_id].nlargest(top_n).round(4).items())[1:],\n",
    "        #\"jaccard\":list(jaccard.loc[project_id].nlargest(top_n).round(4).items()),\n",
    "        \"pearson\":list(pearson.loc[project_id].nlargest(top_n).round(4).items())[1:],\n",
    "        \"euclidean\":list(euclidean.loc[project_id].nlargest(top_n).round(4).items())[1:],\n",
    "        \"manhattan\":list(manhattan.loc[project_id].nlargest(top_n).round(4).items())[1:],\n",
    "        \"tanimoto\":list(tanimoto.loc[project_id].nlargest(top_n).round(4).items())[1:],\n",
    "        \"hamming\":list(hamming.loc[project_id].nlargest(top_n).round(4).items())[1:]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(similarity_comparator)\n",
    "    \n",
    "print(compare_similarity_metrics(voter_matrix, 84))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61027140-55ab-42a5-951e-8cc7eaf1ff6a",
   "metadata": {},
   "source": [
    "#### Checking the highest similarity using only distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1167c0c-d754-4e18-966f-b5beafec2300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# project_ids=list(voter_matrix.columns)\n",
    "# h_cosine={\n",
    "#     \"project_id\":0,\n",
    "#     \"sim_val\":0,\n",
    "#     \"most_sim_project_id\":0\n",
    "# }\n",
    "# # h_jaccard={\n",
    "# #     \"sim_val\":0,\n",
    "# #     \"project_id\":0\n",
    "# # }\n",
    "# h_pearson={\n",
    "#     \"project_id\":0,\n",
    "#     \"sim_val\":0,\n",
    "#     \"most_sim_project_id\":0\n",
    "# }\n",
    "# h_euclidean={\n",
    "#     \"project_id\":0,\n",
    "#     \"sim_val\":0,\n",
    "#     \"most_sim_project_id\":0\n",
    "# }\n",
    "# h_manhattan={\n",
    "#     \"project_id\":0,\n",
    "#     \"sim_val\":0,\n",
    "#     \"most_sim_project_id\":0\n",
    "# }\n",
    "# h_tanimoto={\n",
    "#     \"project_id\":0,\n",
    "#     \"sim_val\":0,\n",
    "#     \"most_sim_project_id\":0\n",
    "# }\n",
    "# h_hamming={\n",
    "#     \"project_id\":0,\n",
    "#     \"sim_val\":0,\n",
    "#     \"most_sim_project_id\":0\n",
    "# }\n",
    "\n",
    "# for project_id in project_ids:\n",
    "#     # print(project_id)\n",
    "#     similarities = compare_similarity_metrics(voter_matrix,project_id,top_n=2)\n",
    "#     #print(similarities)\n",
    "#     cosine = similarities['cosine']\n",
    "#     pearson = similarities['pearson']\n",
    "#     euclidean = similarities['euclidean']\n",
    "#     manhattan = similarities['manhattan']\n",
    "#     tanimoto = similarities['tanimoto']\n",
    "#     hamming = similarities['hamming']\n",
    "\n",
    "#     ##Check cosine highest\n",
    "#     if cosine[0][1] > h_cosine['sim_val']:\n",
    "#         h_cosine['project_id']=project_id\n",
    "#         h_cosine['sim_val'] = cosine[0][1]\n",
    "#         h_cosine['most_sim_project_id']=cosine[0][0]\n",
    "\n",
    "#     ##Check pearson highest\n",
    "#     if pearson[0][1] > h_pearson['sim_val']:\n",
    "#         h_pearson['project_id']=project_id\n",
    "#         h_pearson['sim_val'] = pearson[0][1]\n",
    "#         h_pearson['most_sim_project_id']=pearson[0][0]\n",
    "\n",
    "#     ##Check euclidean highest\n",
    "#     if euclidean[0][1] > h_euclidean['sim_val']:\n",
    "#         h_euclidean['project_id']=project_id\n",
    "#         h_euclidean['sim_val'] = euclidean[0][1]\n",
    "#         h_euclidean['most_sim_project_id']=euclidean[0][0]\n",
    "\n",
    "#     ##Check manhattan highest\n",
    "#     if manhattan[0][1] > h_manhattan['sim_val']:\n",
    "#         h_manhattan['project_id']=project_id\n",
    "#         h_manhattan['sim_val'] = manhattan[0][1]\n",
    "#         h_manhattan['most_sim_project_id']=manhattan[0][0]\n",
    "\n",
    "#     ##Check tanimoto highest\n",
    "#     if tanimoto[0][1] > h_tanimoto['sim_val']:\n",
    "#         h_tanimoto['project_id']=project_id\n",
    "#         h_tanimoto['sim_val'] = tanimoto[0][1]\n",
    "#         h_tanimoto['most_sim_project_id']=tanimoto[0][0]\n",
    "\n",
    "#     ##Check hamming highest\n",
    "#     if hamming[0][1] > h_hamming['sim_val']:\n",
    "#         h_hamming['project_id']=project_id\n",
    "#         h_hamming['sim_val'] = hamming[0][1]\n",
    "#         h_hamming['most_sim_project_id']=hamming[0][0]\n",
    "\n",
    "#     # if project_id == 5:\n",
    "#     #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55978fda-57f9-4cb3-acc3-f1a94ec98713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_id': 84, 'sim_val': 0.677, 'most_sim_project_id': 87}\n",
      "{'project_id': 84, 'sim_val': 0.6731, 'most_sim_project_id': 87}\n",
      "{'project_id': 50, 'sim_val': 0.4641, 'most_sim_project_id': 176}\n",
      "{'project_id': 50, 'sim_val': 0.3022, 'most_sim_project_id': 176}\n",
      "{'project_id': 84, 'sim_val': 0.5116, 'most_sim_project_id': 87}\n",
      "{'project_id': 50, 'sim_val': 0.9991, 'most_sim_project_id': 176}\n"
     ]
    }
   ],
   "source": [
    "# # print(project_ids)\n",
    "# print(h_cosine)\n",
    "# print(h_pearson)\n",
    "# print(h_euclidean)\n",
    "# print(h_manhattan)\n",
    "# print(h_tanimoto)\n",
    "# print(h_hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4630be-4b56-44a8-806e-d16a6dbea855",
   "metadata": {},
   "source": [
    "With the result of the comparison code written 2 blocks up (they are commented because it takes a long time to run them): \n",
    "```\n",
    "cosine -> {'project_id': 84, 'sim_val': 0.677, 'most_sim_project_id': 87}\n",
    "pearson -> {'project_id': 84, 'sim_val': 0.6731, 'most_sim_project_id': 87}\n",
    "euclidean -> {'project_id': 50, 'sim_val': 0.4641, 'most_sim_project_id': 176}\n",
    "manhattan -> {'project_id': 50, 'sim_val': 0.3022, 'most_sim_project_id': 176}\n",
    "tanimoto -> {'project_id': 84, 'sim_val': 0.5116, 'most_sim_project_id': 87}\n",
    "hamming -> {'project_id': 50, 'sim_val': 0.9991, 'most_sim_project_id': 176}\n",
    "```\n",
    "\n",
    "We can see that cosine, pearson and tanimoto produces the same results with different intensities. This is also the case for euclidean, manhattan and hamming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0798c6-c2ea-4602-98f9-eb533cab06ae",
   "metadata": {},
   "source": [
    "## Second similarity study -> calculating distances after embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63958d-3e3a-462b-bd6e-fa82d1218b92",
   "metadata": {},
   "source": [
    "The idea of this second study is to test the performance of different embedding techniques and check their performance regarding project similarity:\n",
    "1- TF-IDF\n",
    "2- Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ad9f4-8bfb-4b1c-9eaf-871028784342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
